{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook provides an example for how to use the PAKKR library in a training and validation pipeline using Fisher's iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Install the packages required for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, NamedTuple, List, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from pakkr import returns, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisData(NamedTuple):\n",
    "    data: np.ndarray\n",
    "    target: np.ndarray\n",
    "    target_names: np.ndarray\n",
    "    feature_names: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSize = float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@returns(stratified_sampler=StratifiedShuffleSplit)\n",
    "def initialise_sampler(test_size) -> Dict[str, StratifiedShuffleSplit]:\n",
    "    \"\"\"\n",
    "    Saves the sampler into the meta to be consumed by a later step.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"stratified_sampler\": StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_data() -> IrisData:\n",
    "    iris = datasets.load_iris()\n",
    "    return IrisData(**{k: iris[k] for k in IrisData._fields})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This annotation informs PAKKR that this step returns two objects, rather than a tuple of two objects\n",
    "@returns(pd.DataFrame, pd.Series)\n",
    "def convert_to_pandas(iris_data: IrisData) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    features = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "    labels = pd.Series(iris_data.target).map({\n",
    "        k: v for k, v in enumerate(iris_data.target_names)\n",
    "    })\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@returns(pd.DataFrame, pd.Series, test_features=pd.DataFrame, test_labels=pd.Series)\n",
    "def create_train_test_split(features: pd.DataFrame, labels: pd.Series, stratified_sampler: StratifiedShuffleSplit):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets.\n",
    "    Saves the test set into the meta to be consumed by a later step.\n",
    "    \"\"\"\n",
    "    train_idx, test_idx = next(stratified_sampler.split(features, labels))\n",
    "    return (\n",
    "        features.loc[train_idx], labels.loc[train_idx], \n",
    "        {\"test_features\": features.loc[test_idx], \"test_labels\": labels.loc[test_idx]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features: pd.DataFrame, labels: pd.Series, clf: BaseEstimator) -> BaseEstimator:\n",
    "    \"\"\"\n",
    "    Extracts clf from meta and fits to training data\n",
    "    \"\"\"\n",
    "    clf.fit(features, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(clf: BaseEstimator, test_features: pd.DataFrame, test_labels: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Extracts test data from meta and scores the classifier\n",
    "    \"\"\"\n",
    "    return clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline: Callable[[BaseEstimator, TestSize], float] = Pipeline(\n",
    "    initialise_sampler,\n",
    "    load_iris_data,\n",
    "    convert_to_pandas,\n",
    "    create_train_test_split,\n",
    "    train_model,\n",
    "    validate_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the pipeline on a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"ovr\", penalty=\"l2\", solver='lbfgs')\n",
    "pipeline(clf=clf, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
